{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nX99zdoffBLg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "from pathlib import Path\n",
    "from neural_poisson.data.prepare import (\n",
    "    extract_surface_data,\n",
    "    uniform_sphere_cameras,\n",
    "    sample_empty_space_points,\n",
    "    subsample_points,\n",
    "    estimate_vector_field_nearest_neighbors\n",
    ")\n",
    "\n",
    "# settings\n",
    "image_size = 512\n",
    "segments = 10\n",
    "device = \"cuda\"\n",
    "model_id = \"1a04e3eab45ca15dd86060f189eb133\"\n",
    "\n",
    "# define the paths\n",
    "root_dir = Path(\"/home/borth/2d-gaussian-splatting/\")\n",
    "shapenet_dir = root_dir / \"data/ShapeNetCoreTiny/02691156\"\n",
    "shapenet_path = shapenet_dir / model_id / \"models/model_normalized.obj\"\n",
    "\n",
    "# load the mesh and the cameras\n",
    "mesh = load_objs_as_meshes([shapenet_path], device=device)\n",
    "cameras = uniform_sphere_cameras(segments=segments, device=device)\n",
    "\n",
    "# visualize a camera\n",
    "elev = 8\n",
    "azim = 1\n",
    "data = extract_surface_data(\n",
    "    camera=cameras[elev + azim * segments],\n",
    "    mesh=mesh,\n",
    "    image_size=image_size,\n",
    ")\n",
    "normal = torch.clip(data[\"normal_map\"][0], 0.0, 1.0)\n",
    "plt.imshow(normal.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = []\n",
    "points = []\n",
    "for camera in cameras[:5]:\n",
    "    data = extract_surface_data(camera=camera, mesh=mesh, image_size=image_size)\n",
    "    normals.append(data[\"normals\"])\n",
    "    points.append(data[\"points\"])\n",
    "normals = torch.cat(normals) \n",
    "points = torch.cat(points) \n",
    "vectors = estimate_vector_field_nearest_neighbors(\n",
    "    points=points,\n",
    "    normals=normals,\n",
    "    query=points,\n",
    "    k=10,\n",
    "    sigma=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points.detach().cpu().numpy())\n",
    "\n",
    "pcd.normals = o3d.utility.Vector3dVector(vectors.detach().cpu().numpy())\n",
    "o3d.visualization.draw_plotly([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cameras[0]\n",
    "data = extract_surface_data(camera=camera, mesh=mesh, image_size=image_size)\n",
    "p_e = sample_empty_space_points(\n",
    "    points=data[\"points\"],\n",
    "    camera=camera,\n",
    "    surface_threshold=1.0,\n",
    "    samples=4,\n",
    ")\n",
    "p_e = subsample_points(points=p_e, resolution=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "k = 20\n",
    "sigma = 1.0\n",
    "threshold = 30 \n",
    "points = data[\"points\"]  # the surface points\n",
    "normals = data[\"normals\"]  # the normals on the surface\n",
    "query = data[\"points\"]  # the target points to evaluate the vector field\n",
    "chunk_size = 1_000\n",
    "normalize = True\n",
    "\n",
    "vectors = []\n",
    "for q in torch.split(query, chunk_size):\n",
    "    # compute the distances\n",
    "    distances = torch.cdist(q, points, p=2)\n",
    "    distances, indices = torch.topk(distances, k, dim=1, largest=False)\n",
    "\n",
    "    # gaussian-weighted average of the k nearest neighbors\n",
    "    weights = torch.exp(-distances / (2 * sigma))\n",
    "\n",
    "    # compute the clusters\n",
    "    cluster_idxs = torch.full_like(indices, -1)\n",
    "    cluster_idxs[:, 0] = 0\n",
    "    for i in range(1, k):\n",
    "        prev_idxs = cluster_idxs[:, :i]\n",
    "        prev_max_cluster = prev_idxs.max(dim=-1).values\n",
    "\n",
    "        # default is just the next index\n",
    "        current_normal = normals[indices][:, i, :]\n",
    "        current_idxs = prev_max_cluster + 1\n",
    "        tmp_cluster_similarity = -torch.ones(q.shape[0]).to(q) # fill with -1\n",
    "\n",
    "        # compute the previous cluster vectors\n",
    "        for j in range(0, i):\n",
    "            # activate the current cluster by disabeling all others\n",
    "            cluster_weights = weights.clone()\n",
    "            cluster_weights[cluster_idxs != j] = 0.0\n",
    "            cluster_vector = (normals[indices] * cluster_weights.unsqueeze(-1)).sum(-2)\n",
    "            cluster_vector /= cluster_weights.sum(-1, keepdim=True)\n",
    "\n",
    "            # compute cosine similartiy between cluster vector and current vector\n",
    "            similarity = (cluster_vector * current_normal).sum(-1)\n",
    "            similarity /= torch.linalg.vector_norm(cluster_vector, dim=-1)\n",
    "            similarity /= torch.linalg.vector_norm(current_normal, dim=-1)\n",
    "\n",
    "            # compute the angle \n",
    "            theta = torch.rad2deg(torch.acos(similarity))\n",
    "\n",
    "            # update the best cluster\n",
    "            mask = (similarity > tmp_cluster_similarity) & (theta <= threshold) \n",
    "            tmp_cluster_similarity[mask] = similarity[mask]\n",
    "            current_idxs[mask] = j\n",
    "\n",
    "        # if there is a cluster that matches \n",
    "        cluster_idxs[:, i] = current_idxs\n",
    "    \n",
    "    # evalute the cluster normals and centers\n",
    "    cluster_vectors = []\n",
    "    cluster_centers = []\n",
    "    for j in range(0, k):\n",
    "        # activate the current cluster by disabeling all others\n",
    "        cluster_weights = weights.clone()\n",
    "        cluster_weights[cluster_idxs != j] = 0.0\n",
    "        cluster_vector = (normals[indices] * cluster_weights.unsqueeze(-1)).sum(-2)\n",
    "        cluster_vector /= cluster_weights.sum(-1, keepdim=True)\n",
    "        cluster_vectors.append(cluster_vector)\n",
    "        # activate the current cluster centers\n",
    "        cluster_center = (points[indices] * cluster_weights.unsqueeze(-1)).sum(-2)\n",
    "        cluster_centers.append(cluster_center)\n",
    "    cluster_centers = torch.stack(cluster_centers, dim=1)  # (P,C,3)\n",
    "    cluster_vectors = torch.stack(cluster_vectors, dim=1)  # (P,C,3)\n",
    "\n",
    "    # select the cluster normal with the clostest cluster center\n",
    "    distances = q.unsqueeze(-2) - cluster_centers\n",
    "    distances = torch.linalg.vector_norm(distances, dim=-1)  # (Q, C)\n",
    "    # reset the distances with no values\n",
    "    idxs = torch.arange(distances.shape[1]).expand(distances.shape[0], -1).to(distances)\n",
    "    mask = idxs > (cluster_idxs.max(dim=-1).values)[..., None]\n",
    "    distances[mask] = torch.nan\n",
    "    distances, indices = torch.topk(distances, 1, dim=1, largest=False)\n",
    "    indices = indices[..., 0]  # just the top 1\n",
    "    # the final cluster vectors\n",
    "    vector = cluster_vectors[torch.arange(cluster_vectors.shape[0]), indices]\n",
    "\n",
    "    # normalize the vector field to contain only normal vectors\n",
    "    if normalize:\n",
    "        vector /= torch.linalg.vector_norm(vector, dim=-1).unsqueeze(-1)\n",
    "    vectors.append(vector)\n",
    "\n",
    "vectors = torch.cat(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = data[\"points\"]  # the surface points\n",
    "normals = data[\"normals\"]  # the normals on the surface\n",
    "query = data[\"points\"]  # the target points to evaluate the vector field\n",
    "\n",
    "vectors = []\n",
    "for q in torch.split(query, chunk_size):\n",
    "    # compute the distances\n",
    "    distances = torch.cdist(q, points, p=2)\n",
    "    distances, indices = torch.topk(distances, 1, dim=1, largest=False)\n",
    "    vector = normals[indices[..., 0]]\n",
    "    # normalize the vector field to contain only normal vectors\n",
    "    if normalize:\n",
    "        vector /= torch.linalg.vector_norm(vector, dim=-1).unsqueeze(-1)\n",
    "    vectors.append(vector)\n",
    "v = torch.cat(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cluster vectors\n",
    "\n",
    "\n",
    "# _cluster_centers = cluster_centers[:100]\n",
    "# _query = query[:100]\n",
    "# _cluster_vectors = cluster_vectors[:100]\n",
    "# _cluster_idx = cluster_idxs[:100].max(dim=-1).values\n",
    "\n",
    "# compute the distances\n",
    "distances = q.unsqueeze(-2) - cluster_centers\n",
    "distances = torch.linalg.vector_norm(distances, dim=-1)  # (Q, C)\n",
    "# reset the distances with no values\n",
    "idxs = torch.arange(distances.shape[1]).expand(distances.shape[0], -1).to(distances)\n",
    "mask = idxs > (cluster_idxs.max(dim=-1).values)[..., None]\n",
    "distances[mask] = torch.nan\n",
    "distances, indices = torch.topk(distances, 1, dim=1, largest=False)\n",
    "indices = indices[..., 0]  # just the top 1\n",
    "# the final cluster vectors\n",
    "vectors = cluster_vectors[torch.arange(cluster_vectors.shape[0]), indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.shape, points.shape, cluster_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape\n",
    "idxs = torch.arange(distances.shape[1]).expand(distances.shape[0], -1).to(distances)\n",
    "mask = idxs > (_cluster_idx)[..., None]\n",
    "distances[mask] = distances.max() + 1\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers[0]\n",
    "query[0]\n",
    "idx = cluster_idxs[0].max(dim=-1).values\n",
    "# distances[0]\n",
    "v = torch.linalg.vector_norm(query[0]-cluster_centers[0], dim=-1)\n",
    "v[idx+1:] = v.max() + 1\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG\n",
    "indices < _cluster_idxs  # the indices should not be able to be bigger then cluster_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.squeeze(-1) <= _cluster_idxs.max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cluster_idxs.max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isnan(cluster_vectors[:, 0, :]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.lin\n",
    "\n",
    "q = query[:100]  # (Q, 3)\n",
    "distances = torch.cdist(cluster_centers, query[:100], p=2)\n",
    "# distances, indices = torch.topk(distances, 1, dim=0, largest=False)\n",
    "# cluster_vector.shape\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5000\n",
    "print(cluster_idxs[idx])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points[indices[idx]].detach().cpu().numpy())\n",
    "pcd.normals = o3d.utility.Vector3dVector(normals[indices[idx]].detach().cpu().numpy())\n",
    "o3d.visualization.draw_plotly([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5000\n",
    "cluster = 4\n",
    "print(cluster_idxs[idx])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points[indices[idx]][cluster_idxs[idx]==cluster].detach().cpu().numpy())\n",
    "pcd.normals = o3d.utility.Vector3dVector(normals[indices[idx]][cluster_idxs[idx]==cluster].detach().cpu().numpy())\n",
    "o3d.visualization.draw_plotly([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points[indices[idx]][cluster_idxs[idx]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals[indices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "prev_idxs = cluster_idxs[:, :k]\n",
    "# default is just the next index\n",
    "prev_max_cluster = prev_idxs.max(dim=-1).values\n",
    "current_idxs = prev_max_cluster + 1\n",
    "current_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_poisson.data.shapenet import ShapeNetCoreDataset\n",
    "from pathlib import Path\n",
    "\n",
    "model_id = \"1a04e3eab45ca15dd86060f189eb133\"\n",
    "# define the paths\n",
    "root_dir = Path(\"/home/borth/2d-gaussian-splatting/\")\n",
    "shapenet_dir = root_dir / \"data/ShapeNetCoreTiny/02691156\"\n",
    "shapenet_path = shapenet_dir / model_id / \"models/model_normalized.obj\"\n",
    "dataset = ShapeNetCoreDataset(\n",
    "    path=shapenet_path,\n",
    "    segments=10,\n",
    "    resolution=0.002,\n",
    "    empty_space_max_ratio=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.points_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(dataset.points_surface.detach().cpu().numpy())\n",
    "\n",
    "pcd.normals = o3d.utility.Vector3dVector(dataset.vectors_surface.detach().cpu().numpy())\n",
    "o3d.visualization.draw_plotly([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if -1 > 0:\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.points_close.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anp_metadata": {
   "path": "notebooks/render_textured_meshes.ipynb"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "colab": {
   "name": "render_textured_meshes.ipynb",
   "provenance": []
  },
  "disseminate_notebook_info": {
   "backup_notebook_id": "569222367081034"
  },
  "kernelspec": {
   "display_name": "2dgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
