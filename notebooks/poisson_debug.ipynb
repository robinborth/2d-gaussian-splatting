{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_poisson.model.neural_poisson import NeuralPoisson\n",
    "\n",
    "ckpt_path = \"/home/borth/2d-gaussian-splatting/logs/2025-02-19/14-49-43/checkpoints/epoch_339.ckpt\"\n",
    "model = NeuralPoisson.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from pytorch3d.ops.marching_cubes import marching_cubes\n",
    "import open3d as o3d\n",
    "\n",
    "# Generate a 3D volumetric grid (e.g., a sphere)\n",
    "grid_size = 32\n",
    "x = torch.linspace(-1, 1, grid_size)\n",
    "y = torch.linspace(-1, 1, grid_size)\n",
    "z = torch.linspace(-1, 1, grid_size)\n",
    "X, Y, Z = torch.meshgrid(x, y, z, indexing='ij')\n",
    "vol = X**2 + Y**2 + Z**2 - 0.5**2  # Implicit surface of a sphere\n",
    "\n",
    "# Apply marching cubes\n",
    "verts, faces = marching_cubes(vol[None], isolevel=0.5)\n",
    "\n",
    "# Convert to NumPy for visualization\n",
    "verts = verts[0].numpy()\n",
    "faces = faces[0].numpy()\n",
    "\n",
    "# Create an Open3D mesh\n",
    "mesh = o3d.geometry.TriangleMesh()\n",
    "mesh.vertices = o3d.utility.Vector3dVector(verts)\n",
    "mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_plotly([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"thesis\", entity=\"robinborth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = (vol[None].permute(1, 0, 2, 3).expand(32, 3, 32, 32) > 0).to(torch.uint8) * 255\n",
    "video = wandb.Video(v, fps=20, format=\"gif\")\n",
    "wandb.log({\"video3\": video})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"/home/borth/2d-gaussian-splatting/test.ckpt\")\n",
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from neural_poisson.model.encoder import MLP\n",
    "\n",
    "mlp = MLP()\n",
    "points = torch.rand((1000, 3))\n",
    "torch.nn.init.uniform_(points, -1.0, 1.0)\n",
    "mlp(points).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "axis = \"x\"\n",
    "\n",
    "grid_vals = torch.linspace(-1.0, 1.0, 256)\n",
    "xs, ys = torch.meshgrid(grid_vals, grid_vals, indexing=\"ij\")\n",
    "zs = torch.zeros_like(xs)\n",
    "if axis == \"x\":\n",
    "    coords = (zs.ravel(), xs.ravel(), ys.ravel())\n",
    "if axis == \"y\":\n",
    "    coords = (xs.ravel(), zs.ravel(), ys.ravel())\n",
    "if axis == \"z\":\n",
    "    coords = (xs.ravel(), ys.ravel(), zs.ravel())\n",
    "grid = torch.stack(coords).reshape(-1, 3)\n",
    "x, _ = self.forward(points.to(self.device))\n",
    "\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Callable\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "class BaseActivation(nn.Module):\n",
    "    @classmethod\n",
    "    def get_name(cls):\n",
    "        return cls.__name__.replace(\"Activation\", \"\").lower()\n",
    "\n",
    "    @classmethod\n",
    "    @torch.no_grad()\n",
    "    def weight_init(self):\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    @torch.no_grad()\n",
    "    def first_layer_weight_init(self):\n",
    "        return None\n",
    "\n",
    "class MLP(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int = 3,\n",
    "        out_features: int = 1,\n",
    "        hidden_features: int = 256,\n",
    "        num_hidden_layers: int = 5,\n",
    "        activation: type[nn.Module] | partial = nn.ReLU,\n",
    "        out_activation: bool = False,\n",
    "        out_bias: bool = True,\n",
    "        weight_init: Callable | None = None,\n",
    "        first_layer_weight_init: Callable | None = None,\n",
    "    ):\n",
    "        # extract the name of the activation\n",
    "        activation_cls = activation\n",
    "        if isinstance(activation, partial):\n",
    "            activation_cls = activation.func\n",
    "\n",
    "        layers: list[Any] = []\n",
    "        names: list[str] = []\n",
    "\n",
    "        # input layers\n",
    "        layers.append(nn.Linear(in_features, hidden_features))\n",
    "        names.append(\"layer_0\")\n",
    "        layers.append(activation())\n",
    "        names.append(f\"{activation_cls.get_name()}_0\")\n",
    "\n",
    "        # hidden layers\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_features, hidden_features))\n",
    "            names.append(f\"layer_{i+1}\")\n",
    "            layers.append(activation())\n",
    "            names.append(f\"{activation_cls.get_name()}_{i+1}\")\n",
    "\n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_features, out_features, bias=out_bias))\n",
    "        names.append(f\"layer_{i+2}\")\n",
    "        if out_activation:\n",
    "            layers.append(activation())\n",
    "            names.append(f\"{activation_cls.get_name()}_{i+2}\")\n",
    "\n",
    "        # initilize the mlp with the layers\n",
    "        ordered_dict = OrderedDict(zip(names, layers))\n",
    "        super().__init__(ordered_dict)\n",
    "\n",
    "        # initilize the weights of the mlp based on the activation function\n",
    "        if weight_init is None:\n",
    "            weight_init = activation_cls.weight_init()\n",
    "        if first_layer_weight_init is None:\n",
    "            first_layer_weight_init = activation_cls.first_layer_weight_init()\n",
    "\n",
    "        if weight_init is not None:\n",
    "            self.apply(weight_init)\n",
    "        if first_layer_weight_init is not None:\n",
    "            self[\"layer_0\"].apply(first_layer_weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "\n",
    "class SinusActivation(BaseActivation):\n",
    "    def __init__(self, w: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.w = w\n",
    "\n",
    "    @classmethod\n",
    "    @torch.no_grad()\n",
    "    def init_weights(cls, m: nn.Module):\n",
    "        if not hasattr(m, \"weight\"):\n",
    "            return\n",
    "        num_input = m.weight.size(-1)\n",
    "        U = np.sqrt(6 / num_input) / 30\n",
    "        m.weight.uniform_(-U, U)\n",
    "    \n",
    "    @classmethod\n",
    "    @torch.no_grad()\n",
    "    def first_layer_weight_init(m: nn.Module):\n",
    "        if not hasattr(m, \"weight\"):\n",
    "            return\n",
    "        num_input = m.weight.size(-1)\n",
    "        U = 1 / num_input \n",
    "        m.weight.uniform_(-U, U)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.sin(self.w * x)\n",
    "\n",
    "class ReLUActivation(BaseActivation, nn.ReLU):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLP(activation=ReLUActivation)\n",
    "mlp\n",
    "# init_weights = SinusActivation.init_weights\n",
    "# init_weights(nn.Linear(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_poisson.model.encoder import MLP, SinusActivation\n",
    "\n",
    "mlp = MLP(activation=SinusActivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_cls.get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "activation = partial(SinusActivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from neural_poisson.data.prepare import load_mesh\n",
    "path = \"/home/borth/2d-gaussian-splatting/logs/2025-02-26/08-43-11/mesh/00000.obj\"\n",
    "_mesh = load_mesh(path)\n",
    "\n",
    "\n",
    "mesh = o3d.geometry.TriangleMesh()\n",
    "mesh.vertices = o3d.utility.Vector3dVector(_mesh.verts_packed().cpu().numpy())\n",
    "mesh.triangles = o3d.utility.Vector3iVector(_mesh.faces_packed().cpu().numpy())\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_plotly([mesh])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
